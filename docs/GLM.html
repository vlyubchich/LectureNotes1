<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Lecture 1 A short path to GLM and GAM | Lecture Notes</title>
  <meta name="description" content="Lecture notes with R examples." />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="Lecture 1 A short path to GLM and GAM | Lecture Notes" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Lecture notes with R examples." />
  <meta name="github-repo" content="vlyubchich/LectureNotes1" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Lecture 1 A short path to GLM and GAM | Lecture Notes" />
  
  <meta name="twitter:description" content="Lecture notes with R examples." />
  

<meta name="author" content="Vyacheslav Lyubchich" />


<meta name="date" content="2020-11-03" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="index.html"/>
<link rel="next" href="references.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Lecture Notes 1</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Prerequisites</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#license"><i class="fa fa-check"></i>License</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="GLM.html"><a href="GLM.html"><i class="fa fa-check"></i><b>1</b> A short path to GLM and GAM</a><ul>
<li class="chapter" data-level="1.1" data-path="GLM.html"><a href="GLM.html#theory"><i class="fa fa-check"></i><b>1.1</b> Theory</a><ul>
<li class="chapter" data-level="1.1.1" data-path="GLM.html"><a href="GLM.html#multiple-linear-regression"><i class="fa fa-check"></i><b>1.1.1</b> Multiple linear regression</a></li>
<li class="chapter" data-level="1.1.2" data-path="GLM.html"><a href="GLM.html#generalized-linear-model-glm"><i class="fa fa-check"></i><b>1.1.2</b> Generalized linear model (GLM)</a></li>
<li class="chapter" data-level="1.1.3" data-path="GLM.html"><a href="GLM.html#generalized-additive-model-gam"><i class="fa fa-check"></i><b>1.1.3</b> Generalized additive model (GAM)</a></li>
<li class="chapter" data-level="1.1.4" data-path="GLM.html"><a href="GLM.html#generalized-additive-model-for-location-scale-and-shape-gamlss"><i class="fa fa-check"></i><b>1.1.4</b> Generalized additive model for location scale and shape (GAMLSS)</a></li>
<li class="chapter" data-level="1.1.5" data-path="GLM.html"><a href="GLM.html#generalized-autoregressive-moving-average-garma"><i class="fa fa-check"></i><b>1.1.5</b> Generalized autoregressive moving average (GARMA)</a></li>
<li class="chapter" data-level="1.1.6" data-path="GLM.html"><a href="GLM.html#summary"><i class="fa fa-check"></i><b>1.1.6</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="GLM.html"><a href="GLM.html#data-example"><i class="fa fa-check"></i><b>1.2</b> Data example</a><ul>
<li class="chapter" data-level="1.2.1" data-path="GLM.html"><a href="GLM.html#simple-linear-regression"><i class="fa fa-check"></i><b>1.2.1</b> Simple linear regression</a></li>
<li class="chapter" data-level="1.2.2" data-path="GLM.html"><a href="GLM.html#polynomial-regression"><i class="fa fa-check"></i><b>1.2.2</b> Polynomial regression</a></li>
<li class="chapter" data-level="1.2.3" data-path="GLM.html"><a href="GLM.html#power-transformation"><i class="fa fa-check"></i><b>1.2.3</b> Power transformation</a></li>
<li class="chapter" data-level="1.2.4" data-path="GLM.html"><a href="GLM.html#generalized-linear-model-glm-1"><i class="fa fa-check"></i><b>1.2.4</b> Generalized linear model (GLM)</a></li>
<li class="chapter" data-level="1.2.5" data-path="GLM.html"><a href="GLM.html#generalized-additive-model-gam-1"><i class="fa fa-check"></i><b>1.2.5</b> Generalized additive model (GAM)</a></li>
<li class="chapter" data-level="1.2.6" data-path="GLM.html"><a href="GLM.html#generalized-additive-model-for-location-scale-and-shape-gamlss-1"><i class="fa fa-check"></i><b>1.2.6</b> Generalized additive model for location scale and shape (GAMLSS)</a></li>
<li class="chapter" data-level="1.2.7" data-path="GLM.html"><a href="GLM.html#next-steps"><i class="fa fa-check"></i><b>1.2.7</b> Next steps</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Lecture Notes</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="GLM" class="section level1">
<h1><span class="header-section-number">Lecture 1</span> A short path to GLM and GAM</h1>
<div id="theory" class="section level2">
<h2><span class="header-section-number">1.1</span> Theory</h2>
<p>This is a brief overview of popular regression models, based on <span class="citation">Lyubchich et al. (<a href="#ref-Lyubchich:etal:2019:wires" role="doc-biblioref">2019</a>)</span>.</p>
<p>Consider a general regression framework:
<span class="math display" id="eq:general">\[\begin{equation}
    \tag{1.1}
    \mathbf{Y} = \boldsymbol{\mu} + \boldsymbol{\epsilon},
\end{equation}\]</span>
where <span class="math inline">\(\mathbf{Y}\)</span> is an <span class="math inline">\(n\times1\)</span> column vector comprising observations of the variable of interest (response variable); <span class="math inline">\(\boldsymbol{\mu}\)</span> is an <span class="math inline">\(n\times1\)</span> column vector of expected values <span class="math inline">\(\mathrm{E}(Y_i) \equiv \mu_i\)</span>; <span class="math inline">\(\boldsymbol{\epsilon}\)</span> is an <span class="math inline">\(n\times1\)</span> column vector of zero-mean random deviations from the expected values, <span class="math inline">\(i = 1,\ldots,n\)</span>; and <span class="math inline">\(n\)</span> is the sample size.</p>
<div id="multiple-linear-regression" class="section level3">
<h3><span class="header-section-number">1.1.1</span> Multiple linear regression</h3>
<p>In case of a multiple linear regression, the mean response takes the form
<span class="math display" id="eq:mlr">\[\begin{equation}
    \tag{1.2}
    \boldsymbol{\mu} = \mathbf{X}\boldsymbol{\beta},
\end{equation}\]</span>
where <span class="math inline">\(\mathbf{X}\)</span> is an <span class="math inline">\(n\times(d+1)\)</span> matrix with one column of 1’s for fitting an intercept in the model and the remaining <span class="math inline">\(d\)</span> columns for <span class="math inline">\(d\)</span> correlates (that is, explanatory variables) associated with the response variable; <span class="math inline">\(\boldsymbol{\beta}\)</span> is a <span class="math inline">\((d+1)\times 1\)</span> column vector of regression coefficients.</p>
<p>The estimation of regression model <a href="GLM.html#eq:mlr">(1.2)</a> and further inference are based on a <em>number of assumptions</em> about the validity of the form of the model (i.e., linearity of relationships between <span class="math inline">\(Y\)</span> and each <span class="math inline">\(X\)</span> variable), linear independence of the variables in <span class="math inline">\(\mathbf{X}\)</span>, relatively equal importance of all the <span class="math inline">\(n\)</span> observations, as well as uncorrelatedness, homoscedasticity, and normality of errors <span class="math inline">\(\boldsymbol{\epsilon}\)</span> <span class="citation">(Chatterjee and Hadi <a href="#ref-Chatterjee:Hadi:2006" role="doc-biblioref">2006</a>)</span>. However, the assumption of normality is often violated, and model <a href="GLM.html#eq:mlr">(1.2)</a> in its classical formulation cannot be used in majority of applied problems.</p>
</div>
<div id="generalized-linear-model-glm" class="section level3">
<h3><span class="header-section-number">1.1.2</span> Generalized linear model (GLM)</h3>
<p>Generalized linear models (GLMs) help to overcome the violation of normality assumption by extending the applicability of model <a href="GLM.html#eq:mlr">(1.2)</a> to exponential-type distributions, such as Poisson, binomial, and gamma <span class="citation">(Wood <a href="#ref-Wood:2006book" role="doc-biblioref">2006</a>)</span>. In GLMs, distribution of <span class="math inline">\(Y_i\)</span> belongs to a family of <em>exponential distributions</em>, and a smooth monotonic link function <span class="math inline">\(g(\cdot)\)</span> is applied to transform the response variable:
<span class="math display" id="eq:glm">\[\begin{equation}
    \tag{1.3}
    g(\boldsymbol{\mu}) = \mathbf{X}\boldsymbol{\beta}.
\end{equation}\]</span>
A distribution belongs to the exponential family of distributions if its probability density function can be written as:</p>
<p><span class="math display">\[f_{\theta}(y) = \exp[{y\theta - b(\theta)}/a(\phi) + c(y, \phi)],\]</span>
where <span class="math inline">\(b\)</span>, <span class="math inline">\(a\)</span>, and <span class="math inline">\(c\)</span> are arbitrary functions, <span class="math inline">\(\phi\)</span> and arbitrary ‘scale’ parameter, and <span class="math inline">\(\theta\)</span> is the ‘canonical parameter’ of the distribution. For normal distribution, <span class="math inline">\(\theta = \mu\)</span> and <span class="math inline">\(a(\phi) = \phi= \sigma^2\)</span> <span class="citation">(Wood <a href="#ref-Wood:2006book" role="doc-biblioref">2006</a>)</span>.</p>
<p>Canonical link functions are identity, ln, and inverse for normal, Poisson, and gamma distributions, respectively. After such transformation, however, model <a href="GLM.html#eq:glm">(1.3)</a> still assumes linear relationships between each of the original variables in <span class="math inline">\(\mathbf{X}\)</span> and the transformed response. Model <a href="GLM.html#eq:glm">(1.3)</a> is applicable when the link function successfully linearizes the relationship between the risk variable and a predictor. In other cases, especially if there are multiple predictors, additional work on re-specifying the model may be required. For example, relationships between the response variable and different predictors may require different linearizing transformations, the relationships may be non-monotonic, and many of them may be thresholded (i.e., the effect of a covariate <span class="math inline">\(X\)</span> is pronounced only when <span class="math inline">\(X\)</span> takes on values from a certain range, such as the effect of daily precipitation on sediment concentrations in the streams is not noticeable below certain precipitation threshold).</p>
</div>
<div id="generalized-additive-model-gam" class="section level3">
<h3><span class="header-section-number">1.1.3</span> Generalized additive model (GAM)</h3>
<p>One way we can capture highly non-linear relationships is by inclusion of additional transformed <span class="math inline">\(X\)</span>-variables, such as power transformed or thresholded variables (e.g., <span class="math inline">\(X_i^2\)</span>; <span class="math inline">\(\max(0, X_j - a)\)</span>). However, adding tightly linked variables into the design matrix <span class="math inline">\(\mathbf{X}\)</span> may introduce multicollinearity and affect the inference. An alternative way of modeling non-linearities is replacing the original variables with those individually transformed using smooth (nonparametric) functions, such as in a generalized additive model (GAM):
<span class="math display" id="eq:gam">\[\begin{equation}
    \tag{1.4}
    g(\boldsymbol{\mu}) = \mathbf{X}^*\boldsymbol{\beta}^* + f_1(X_1) + f_2(X_2) + f_3(X_3,X_4) + \ldots,
\end{equation}\]</span>
where <span class="math inline">\(Y_i\)</span> still follows one of the exponential-family distributions; <span class="math inline">\(\mathbf{X}^*\)</span> and <span class="math inline">\(\boldsymbol{\beta}^*\)</span> are the remaining variables and associated coefficients in strictly parametric formulation; <span class="math inline">\(f(\cdot)\)</span> are smooth functions, often represented by regression splines <span class="citation">(Wood <a href="#ref-Wood:2006book" role="doc-biblioref">2006</a>)</span>. Model <a href="GLM.html#eq:gam">(1.4)</a> can easily deal with deviations from normality and can accommodate non-linearity and non-monotonicity of individual relationships, however, the model still fails to address the issue of remaining dependencies in the errors, e.g., see <span class="citation">Kohn, Schimek, and Smith (<a href="#ref-Kohn:etal:2000" role="doc-biblioref">2000</a>)</span>.</p>
</div>
<div id="generalized-additive-model-for-location-scale-and-shape-gamlss" class="section level3">
<h3><span class="header-section-number">1.1.4</span> Generalized additive model for location scale and shape (GAMLSS)</h3>
<p>An extension of model <a href="GLM.html#eq:gam">(1.4)</a> by <span class="citation">Stasinopoulos and Rigby (<a href="#ref-Stasinopoulos:Rigby:2007" role="doc-biblioref">2007</a>)</span> to <span class="math inline">\(k=1,2,3,4\)</span> parameters <span class="math inline">\(\boldsymbol{\theta}_k\)</span> of a distribution (not just the location parameter <span class="math inline">\(\mu_i\)</span>, but also scale <span class="math inline">\(\sigma_i\)</span>, and shape – skewness and kurtosis; can be generalized for <span class="math inline">\(k&gt;4\)</span>) allows fitting <span class="math inline">\(k\)</span> individual models
<span class="math display" id="eq:gamlss">\[\begin{equation}
   \tag{1.5}
    g_k(\boldsymbol{\theta}_k) = h_k\left(\mathbf{X}_k,\boldsymbol{\beta}_k\right) + \sum_{j=1}^{J_k}h_{jk}(\mathbf{x}_{jk}),
\end{equation}\]</span>
where <span class="math inline">\(k=1\)</span> produces model for the mean; <span class="math inline">\(h_k(\cdot)\)</span> and <span class="math inline">\(h_{jk}(\cdot)\)</span> are non-linear functions; <span class="math inline">\(\boldsymbol{\beta}_k\)</span> is a parameter vector of length <span class="math inline">\(J_k\)</span>; <span class="math inline">\(\mathbf{X}_k\)</span> is an <span class="math inline">\(n\times J_k\)</span> design matrix; <span class="math inline">\(\mathbf{x}_{jk}\)</span> are vectors of length <span class="math inline">\(n\)</span>. The additive terms in this generalized additive model for location scale and shape (GAMLSS) provide a flexible framework to specify random effects and correlation structure as in mixed effects models <span class="citation">(Zuur et al. <a href="#ref-Zuur:etal:2009" role="doc-biblioref">2009</a>)</span>; see Table 3 by <span class="citation">Stasinopoulos and Rigby (<a href="#ref-Stasinopoulos:Rigby:2007" role="doc-biblioref">2007</a>)</span> for other possible specifications of the additive terms. Hence, models of the form <a href="GLM.html#eq:gamlss">(1.5)</a> may be a good choice for insurance problems, because such models accommodate non-normal distributions, possibly highly non-linear relationships, and spatiotemporal dependencies in the data.</p>
</div>
<div id="generalized-autoregressive-moving-average-garma" class="section level3">
<h3><span class="header-section-number">1.1.5</span> Generalized autoregressive moving average (GARMA)</h3>
<p>Another group of models, called generalized autoregressive moving average (GARMA), was developed by <span class="citation">Benjamin, Rigby, and Stasinopoulos (<a href="#ref-Benjamin:etal:2003" role="doc-biblioref">2003</a>)</span> as a combination of GLM <a href="GLM.html#eq:glm">(1.3)</a> with Box–Jenkins approach of modeling temporal dependence:
<span class="math display" id="eq:garma">\[\begin{equation}
    \tag{1.6}
    g(\boldsymbol{\mu}_t) = \eta_t = \mathbf{X}_t\boldsymbol{\beta} + \sum_{j=1}^p{\phi_j \{ g(y_{t-j}) - \mathbf{X}_{t-j}\boldsymbol{\beta}\}} + \sum_{j=1}^q \theta_j \left\{ g(y_{t-j}) - \eta_{t-j}\right\},
\end{equation}\]</span>
where <span class="math inline">\(t=1,\ldots,n\)</span> is the time index; <span class="math inline">\(\phi_j\)</span>, <span class="math inline">\(j=1,\ldots,p\)</span>, are autoregressive coefficients; <span class="math inline">\(\theta_j\)</span>, <span class="math inline">\(j=1,\ldots,q\)</span>, are moving average coefficients, and <span class="math inline">\(p\)</span> and <span class="math inline">\(q\)</span> are the autoregressive and moving average orders, respectively. Model <a href="GLM.html#eq:garma">(1.6)</a> is efficient for dealing with individual time series.</p>
</div>
<div id="summary" class="section level3">
<h3><span class="header-section-number">1.1.6</span> Summary</h3>
<p>Notice that the issue of different reliability of individual measurements can be solved in models <a href="GLM.html#eq:mlr">(1.2)</a>–<a href="GLM.html#eq:garma">(1.6)</a> by introducing pre-defined weights in the estimation process. An automatic tuning of weights for improved model performance is possible with a number of boosting algorithms, such as AdaBoost.M1 <span class="citation">(Hastie, Tibshirani, and Friedman <a href="#ref-Hastie:etal:2009" role="doc-biblioref">2009</a>)</span>.</p>
<p>Overall, model <a href="GLM.html#eq:gamlss">(1.5)</a> is a powerful and flexible choice for a variety of applied problems, when data exhibit complex spatiotemporal dependence and do not adhere to commonly used distributions, such as normal or Poisson.</p>
<p>The challenges of using the above statistical models include the choice of predictors, their transformations, distribution of the response variable, and model specification, which can be attempted with a variety of criteria (for example, Akaike and Bayesian information criteria – AIC and BIC) ubiquitous in statistical literature. Machine learning approaches offer more flexibility by relaxing the assumptions about distributions and forms of relationships, and providing automated solutions for learning meta-features from large amounts of data. At the same time, the large number of tuning parameters that inhere in a machine learning (especially in deep learning) method and their ability of changing the output or extending the computing time dramatically put out a warning for cautious implementation and interpretation of those methods.</p>

</div>
</div>
<div id="data-example" class="section level2">
<h2><span class="header-section-number">1.2</span> Data example</h2>
<p>Load needed packages: dplyr <span class="citation">(Wickham et al. <a href="#ref-R-dplyr" role="doc-biblioref">2020</a>)</span>, etc.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="GLM.html#cb1-1"></a><span class="kw">library</span>(dplyr)</span>
<span id="cb1-2"><a href="GLM.html#cb1-2"></a><span class="kw">library</span>(GGally)</span>
<span id="cb1-3"><a href="GLM.html#cb1-3"></a><span class="kw">library</span>(plotly)</span>
<span id="cb1-4"><a href="GLM.html#cb1-4"></a><span class="kw">set.seed</span>(<span class="dv">123</span>)</span></code></pre></div>
<p>Select average water quality measurements in Chesapeake Bay for December 2010:</p>
<ul>
<li>Station: station at which the measurements were taken. There are 133 stations in the data file; at this time, we disregard the spatial patterns;</li>
<li>DO: concentration of dissolved oxygen;</li>
<li>CHLA: concentration of chlorophyll-a;</li>
<li>SALINITY: water salinity;</li>
<li>WTEMP: water temperature;</li>
<li>TSS: concentration of total suspended solids;</li>
<li>TN: concentration of total nitrogen;</li>
<li>TP: concentration of total phosphorus.</li>
</ul>
<p>Then try modeling TP with different methods.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="GLM.html#cb2-1"></a>D &lt;-<span class="st"> </span><span class="kw">read.csv</span>(<span class="st">&quot;./data/CBmonthly.csv&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb2-2"><a href="GLM.html#cb2-2"></a><span class="st">    </span>dplyr<span class="op">::</span><span class="kw">filter</span>(., Year <span class="op">==</span><span class="st"> </span><span class="dv">2010</span> <span class="op">&amp;</span><span class="st"> </span>Month <span class="op">==</span><span class="st"> </span><span class="dv">12</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb2-3"><a href="GLM.html#cb2-3"></a><span class="st">    </span>dplyr<span class="op">::</span><span class="kw">select</span>(Station, DO, CHLA, SALINITY, WTEMP, TSS, TN, TP)</span>
<span id="cb2-4"><a href="GLM.html#cb2-4"></a><span class="kw">str</span>(D)</span></code></pre></div>
<pre><code>## &#39;data.frame&#39;:    133 obs. of  8 variables:
##  $ Station : chr  &quot;CB1.1&quot; &quot;CB2.1&quot; &quot;CB2.2&quot; &quot;CB3.1&quot; ...
##  $ DO      : num  14.2 14.2 13.4 12.7 12.2 ...
##  $ CHLA    : num  1.78 1.78 1.07 1.87 2.56 ...
##  $ SALINITY: num  0 0 0.9 3.12 5.63 ...
##  $ WTEMP   : num  0.1 0.1 0.6 0.9 1.6 ...
##  $ TSS     : num  15.6 15.6 16.2 18.4 12 ...
##  $ TN      : num  1.66 1.66 1.55 1.25 1.12 ...
##  $ TP      : num  0.045 0.045 0.0403 0.0436 0.036 ...</code></pre>
<p>Plot data</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="GLM.html#cb4-1"></a>p &lt;-<span class="st"> </span><span class="kw">ggpairs</span>(D[,<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb4-2"><a href="GLM.html#cb4-2"></a>p <span class="co">#ggplotly(p)</span></span></code></pre></div>
<p><img src="Lecture-notes-1_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
<div id="simple-linear-regression" class="section level3">
<h3><span class="header-section-number">1.2.1</span> Simple linear regression</h3>
<p>For the simplest model, select a variable with the strongest correlation with TP: it is TSS.
Our simple linear regression model is</p>
<p><span class="math display">\[TP_i = \beta_0 + \beta_1 TSS_i + \epsilon_i,\]</span>
where <span class="math inline">\(i = 1,\ldots,n\)</span> (<span class="math inline">\(n =\)</span> 133 is the sample size).</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="GLM.html#cb5-1"></a>m1 &lt;-<span class="st"> </span><span class="kw">lm</span>(TP <span class="op">~</span><span class="st"> </span>TSS, <span class="dt">data =</span> D)</span>
<span id="cb5-2"><a href="GLM.html#cb5-2"></a><span class="kw">summary</span>(m1)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = TP ~ TSS, data = D)
## 
## Residuals:
##       Min        1Q    Median        3Q       Max 
## -0.041079 -0.010033 -0.001276  0.006457  0.043831 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 1.860e-02  1.801e-03   10.33   &lt;2e-16 ***
## TSS         1.755e-03  9.059e-05   19.37   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.01375 on 131 degrees of freedom
## Multiple R-squared:  0.7412, Adjusted R-squared:  0.7393 
## F-statistic: 375.3 on 1 and 131 DF,  p-value: &lt; 2.2e-16</code></pre>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="GLM.html#cb7-1"></a><span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">2</span>))</span>
<span id="cb7-2"><a href="GLM.html#cb7-2"></a><span class="kw">plot</span>(m1, <span class="dt">las =</span> <span class="dv">1</span>)</span></code></pre></div>
<p><img src="Lecture-notes-1_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="GLM.html#cb8-1"></a><span class="kw">plot</span>(TP <span class="op">~</span><span class="st"> </span>TSS, <span class="dt">data =</span> D, <span class="dt">las =</span> <span class="dv">1</span>)</span>
<span id="cb8-2"><a href="GLM.html#cb8-2"></a><span class="kw">abline</span>(m1, <span class="dt">lwd =</span> <span class="dv">2</span>, <span class="dt">col =</span> <span class="st">&quot;blue&quot;</span>)</span></code></pre></div>
<p><img src="Lecture-notes-1_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<p>The model clearly has problems.</p>
</div>
<div id="polynomial-regression" class="section level3">
<h3><span class="header-section-number">1.2.2</span> Polynomial regression</h3>
<p>Without modifying the response variable, apply a polynomial transformation to the explanatory variable, for example quadratic (informed by the plot). Our polynomial regression model is</p>
<p><span class="math display">\[TP_i = \beta_0 + \beta_1 TSS_i + \beta_2 TSS^2_i + \epsilon_i,\]</span>
Use function poly to create orthogonal polynomials:</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="GLM.html#cb9-1"></a>m2 &lt;-<span class="st"> </span><span class="kw">lm</span>(TP <span class="op">~</span><span class="st"> </span><span class="kw">poly</span>(TSS, <span class="dv">2</span>), <span class="dt">data =</span> D)</span>
<span id="cb9-2"><a href="GLM.html#cb9-2"></a><span class="kw">summary</span>(m2)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = TP ~ poly(TSS, 2), data = D)
## 
## Residuals:
##       Min        1Q    Median        3Q       Max 
## -0.021327 -0.010286 -0.000931  0.005123  0.040019 
## 
## Coefficients:
##                Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)    0.044747   0.001156   38.72  &lt; 2e-16 ***
## poly(TSS, 2)1  0.266399   0.013327   19.99  &lt; 2e-16 ***
## poly(TSS, 2)2 -0.041043   0.013327   -3.08  0.00253 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.01333 on 130 degrees of freedom
## Multiple R-squared:  0.7588, Adjusted R-squared:  0.7551 
## F-statistic: 204.5 on 2 and 130 DF,  p-value: &lt; 2.2e-16</code></pre>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="GLM.html#cb11-1"></a><span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">2</span>))</span>
<span id="cb11-2"><a href="GLM.html#cb11-2"></a><span class="kw">plot</span>(m2, <span class="dt">las =</span> <span class="dv">1</span>)</span></code></pre></div>
<p><img src="Lecture-notes-1_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="GLM.html#cb12-1"></a><span class="kw">plot</span>(TP <span class="op">~</span><span class="st"> </span>TSS, <span class="dt">data =</span> D, <span class="dt">las =</span> <span class="dv">1</span>)</span>
<span id="cb12-2"><a href="GLM.html#cb12-2"></a>pr &lt;-<span class="st"> </span><span class="kw">predict</span>(m2, <span class="dt">newdata =</span> D, <span class="dt">se.fit =</span> <span class="ot">TRUE</span>)</span>
<span id="cb12-3"><a href="GLM.html#cb12-3"></a><span class="kw">with</span>(D, <span class="kw">lines</span>(<span class="dt">x =</span> <span class="kw">sort</span>(TSS), <span class="dt">y =</span> pr<span class="op">$</span>fit[<span class="kw">order</span>(TSS)],</span>
<span id="cb12-4"><a href="GLM.html#cb12-4"></a>              <span class="dt">lwd =</span> <span class="dv">2</span>, <span class="dt">col =</span> <span class="st">&quot;blue&quot;</span>))</span></code></pre></div>
<p><img src="Lecture-notes-1_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
</div>
<div id="power-transformation" class="section level3">
<h3><span class="header-section-number">1.2.3</span> Power transformation</h3>
<p>Apply Box–Cox method to select a power transformation for the response variable:</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="GLM.html#cb13-1"></a><span class="kw">library</span>(MASS)</span>
<span id="cb13-2"><a href="GLM.html#cb13-2"></a><span class="kw">boxcox</span>(m1)</span></code></pre></div>
<p><img src="Lecture-notes-1_files/figure-html/unnamed-chunk-10-1.png" width="672" /></p>
<p>Check linearity after applying the transformation</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb14-1"><a href="GLM.html#cb14-1"></a><span class="kw">plot</span>(<span class="kw">sqrt</span>(TP) <span class="op">~</span><span class="st"> </span>TSS, <span class="dt">data =</span> D, <span class="dt">las =</span> <span class="dv">1</span>)</span></code></pre></div>
<p><img src="Lecture-notes-1_files/figure-html/unnamed-chunk-11-1.png" width="672" /></p>
<p>Hence, the model looks like</p>
<p><span class="math display">\[\sqrt{TP_i} = \beta_0 + \beta_1 TSS_i + \epsilon_i\]</span></p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="GLM.html#cb15-1"></a>m3 &lt;-<span class="st"> </span><span class="kw">lm</span>(<span class="kw">sqrt</span>(TP) <span class="op">~</span><span class="st"> </span>TSS, <span class="dt">data =</span> D)</span>
<span id="cb15-2"><a href="GLM.html#cb15-2"></a><span class="kw">summary</span>(m3)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = sqrt(TP) ~ TSS, data = D)
## 
## Residuals:
##       Min        1Q    Median        3Q       Max 
## -0.090920 -0.017810 -0.002486  0.018862  0.082065 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 0.1470414  0.0042308   34.76   &lt;2e-16 ***
## TSS         0.0037651  0.0002128   17.69   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.03231 on 131 degrees of freedom
## Multiple R-squared:  0.7049, Adjusted R-squared:  0.7027 
## F-statistic:   313 on 1 and 131 DF,  p-value: &lt; 2.2e-16</code></pre>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb17-1"><a href="GLM.html#cb17-1"></a><span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">2</span>))</span>
<span id="cb17-2"><a href="GLM.html#cb17-2"></a><span class="kw">plot</span>(m3, <span class="dt">las =</span> <span class="dv">1</span>)</span></code></pre></div>
<p><img src="Lecture-notes-1_files/figure-html/unnamed-chunk-13-1.png" width="672" /></p>
<p>When plotting the fitted values, remember to back-transform</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb18-1"><a href="GLM.html#cb18-1"></a><span class="kw">plot</span>(TP <span class="op">~</span><span class="st"> </span>TSS, <span class="dt">data =</span> D, <span class="dt">las =</span> <span class="dv">1</span>)</span>
<span id="cb18-2"><a href="GLM.html#cb18-2"></a>pr &lt;-<span class="st"> </span><span class="kw">predict</span>(m3, <span class="dt">newdata =</span> D, <span class="dt">se.fit =</span> <span class="ot">TRUE</span>)</span>
<span id="cb18-3"><a href="GLM.html#cb18-3"></a><span class="kw">with</span>(D, <span class="kw">lines</span>(<span class="dt">x =</span> <span class="kw">sort</span>(TSS), <span class="dt">y =</span> pr<span class="op">$</span>fit[<span class="kw">order</span>(TSS)]<span class="op">^</span><span class="dv">2</span>,</span>
<span id="cb18-4"><a href="GLM.html#cb18-4"></a>              <span class="dt">lwd =</span> <span class="dv">2</span>, <span class="dt">col =</span> <span class="st">&quot;blue&quot;</span>))</span></code></pre></div>
<p><img src="Lecture-notes-1_files/figure-html/unnamed-chunk-14-1.png" width="672" /></p>
</div>
<div id="generalized-linear-model-glm-1" class="section level3">
<h3><span class="header-section-number">1.2.4</span> Generalized linear model (GLM)</h3>
<p>Review the distribution of the response variable and select an appropriate one</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb19-1"><a href="GLM.html#cb19-1"></a>?family</span></code></pre></div>
<p>Check linearity after applying the transformation (link function for the selected distribution)</p>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb20-1"><a href="GLM.html#cb20-1"></a><span class="kw">plot</span>(<span class="kw">log</span>(TP) <span class="op">~</span><span class="st"> </span>TSS, <span class="dt">data =</span> D, <span class="dt">las =</span> <span class="dv">1</span>)</span></code></pre></div>
<p><img src="Lecture-notes-1_files/figure-html/unnamed-chunk-16-1.png" width="672" /></p>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb21-1"><a href="GLM.html#cb21-1"></a>m4 &lt;-<span class="st"> </span><span class="kw">glm</span>(TP <span class="op">~</span><span class="st"> </span>TSS, <span class="dt">data =</span> D, <span class="dt">family =</span> <span class="kw">Gamma</span>(<span class="dt">link =</span> <span class="st">&quot;log&quot;</span>))</span>
<span id="cb21-2"><a href="GLM.html#cb21-2"></a><span class="kw">summary</span>(m4)</span></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = TP ~ TSS, family = Gamma(link = &quot;log&quot;), data = D)
## 
## Deviance Residuals: 
##      Min        1Q    Median        3Q       Max  
## -0.77706  -0.20733  -0.01593   0.17525   0.80973  
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) -3.71136    0.04453  -83.34   &lt;2e-16 ***
## TSS          0.03359    0.00224   15.00   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for Gamma family taken to be 0.1156311)
## 
##     Null deviance: 42.986  on 132  degrees of freedom
## Residual deviance: 15.270  on 131  degrees of freedom
## AIC: -771.27
## 
## Number of Fisher Scoring iterations: 5</code></pre>
<p>Hence, the model is
<span class="math display">\[TP_i \sim Gamma\]</span>
<span class="math display">\[\ln(\text{E}(TP_i)) = \beta_0 + \beta_1 TSS_i\]</span></p>
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb23-1"><a href="GLM.html#cb23-1"></a><span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">2</span>))</span>
<span id="cb23-2"><a href="GLM.html#cb23-2"></a><span class="kw">plot</span>(m4, <span class="dt">las =</span> <span class="dv">1</span>)</span></code></pre></div>
<p><img src="Lecture-notes-1_files/figure-html/unnamed-chunk-18-1.png" width="672" /></p>
<p>When plotting the fitted values, remember to back-transform</p>
<div class="sourceCode" id="cb24"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb24-1"><a href="GLM.html#cb24-1"></a><span class="kw">plot</span>(TP <span class="op">~</span><span class="st"> </span>TSS, <span class="dt">data =</span> D, <span class="dt">las =</span> <span class="dv">1</span>)</span>
<span id="cb24-2"><a href="GLM.html#cb24-2"></a>pr &lt;-<span class="st"> </span><span class="kw">predict</span>(m4, <span class="dt">newdata =</span> D, <span class="dt">se.fit =</span> <span class="ot">TRUE</span>)</span>
<span id="cb24-3"><a href="GLM.html#cb24-3"></a><span class="kw">with</span>(D, <span class="kw">lines</span>(<span class="dt">x =</span> <span class="kw">sort</span>(TSS), <span class="dt">y =</span> <span class="kw">exp</span>(pr<span class="op">$</span>fit[<span class="kw">order</span>(TSS)]),</span>
<span id="cb24-4"><a href="GLM.html#cb24-4"></a>              <span class="dt">lwd =</span> <span class="dv">2</span>, <span class="dt">col =</span> <span class="st">&quot;blue&quot;</span>))</span></code></pre></div>
<p><img src="Lecture-notes-1_files/figure-html/unnamed-chunk-19-1.png" width="672" /></p>
</div>
<div id="generalized-additive-model-gam-1" class="section level3">
<h3><span class="header-section-number">1.2.5</span> Generalized additive model (GAM)</h3>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb25-1"><a href="GLM.html#cb25-1"></a><span class="kw">library</span>(mgcv)</span>
<span id="cb25-2"><a href="GLM.html#cb25-2"></a>m5 &lt;-<span class="st"> </span><span class="kw">gam</span>(TP <span class="op">~</span><span class="st"> </span><span class="kw">s</span>(TSS), <span class="dt">data =</span> D, <span class="dt">family =</span> <span class="kw">Gamma</span>(<span class="dt">link =</span> log))</span>
<span id="cb25-3"><a href="GLM.html#cb25-3"></a><span class="kw">summary</span>(m5)</span></code></pre></div>
<pre><code>## 
## Family: Gamma 
## Link function: log 
## 
## Formula:
## TP ~ s(TSS)
## 
## Parametric coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) -3.22297    0.02675  -120.5   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Approximate significance of smooth terms:
##          edf Ref.df     F p-value    
## s(TSS) 5.597  6.614 43.63  &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## R-sq.(adj) =  0.789   Deviance explained = 71.9%
## GCV = 0.10045  Scale est. = 0.095193  n = 133</code></pre>
<p>The model is
<span class="math display">\[TP_i \sim Gamma\]</span>
<span class="math display">\[\ln(\text{E}(TP_i)) = \beta_0 + f(TSS_i)\]</span></p>
<p>Visualize the smooth term. For identifiability, sum of the values of each curve, at the observed covariate values, must be zero.</p>
<div class="sourceCode" id="cb27"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb27-1"><a href="GLM.html#cb27-1"></a><span class="kw">plot</span>(m5, <span class="dt">las =</span> <span class="dv">1</span>)</span></code></pre></div>
<p><img src="Lecture-notes-1_files/figure-html/unnamed-chunk-21-1.png" width="672" /></p>
<p>Diagnostics</p>
<div class="sourceCode" id="cb28"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb28-1"><a href="GLM.html#cb28-1"></a><span class="kw">gam.check</span>(m5)</span></code></pre></div>
<p><img src="Lecture-notes-1_files/figure-html/unnamed-chunk-22-1.png" width="672" /></p>
<pre><code>## 
## Method: GCV   Optimizer: outer newton
## full convergence after 3 iterations.
## Gradient range [1.729043e-10,1.729043e-10]
## (score 0.1004541 &amp; scale 0.09519291).
## Hessian positive definite, eigenvalue range [0.0008269258,0.0008269258].
## Model rank =  10 / 10 
## 
## Basis dimension (k) checking results. Low p-value (k-index&lt;1) may
## indicate that k is too low, especially if edf is close to k&#39;.
## 
##         k&#39; edf k-index p-value
## s(TSS) 9.0 5.6    0.91    0.18</code></pre>
<p>If family is not Gaussian (more specifically, if the link function is not identity), remember to back-transform</p>
<div class="sourceCode" id="cb30"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb30-1"><a href="GLM.html#cb30-1"></a><span class="kw">plot</span>(TP <span class="op">~</span><span class="st"> </span>TSS, <span class="dt">data =</span> D, <span class="dt">las =</span> <span class="dv">1</span>)</span>
<span id="cb30-2"><a href="GLM.html#cb30-2"></a>pr &lt;-<span class="st"> </span><span class="kw">predict</span>(m5, <span class="dt">newdata =</span> D, <span class="dt">se.fit =</span> <span class="ot">TRUE</span>)</span>
<span id="cb30-3"><a href="GLM.html#cb30-3"></a><span class="kw">with</span>(D, <span class="kw">lines</span>(<span class="dt">x =</span> <span class="kw">sort</span>(TSS), <span class="dt">y =</span> <span class="kw">exp</span>(pr<span class="op">$</span>fit[<span class="kw">order</span>(TSS)]),</span>
<span id="cb30-4"><a href="GLM.html#cb30-4"></a>              <span class="dt">lwd =</span> <span class="dv">2</span>, <span class="dt">col =</span> <span class="st">&quot;blue&quot;</span>))</span></code></pre></div>
<p><img src="Lecture-notes-1_files/figure-html/unnamed-chunk-23-1.png" width="672" /></p>
</div>
<div id="generalized-additive-model-for-location-scale-and-shape-gamlss-1" class="section level3">
<h3><span class="header-section-number">1.2.6</span> Generalized additive model for location scale and shape (GAMLSS)</h3>
<p>Note that variance of residuals slightly increases with TSS. We can</p>
<ul>
<li>use generalized least squares (GLS) to transform the variables and stabilize the variance, or</li>
<li>fit a separate model for variance, similar to the model for the mean.</li>
</ul>
<p>Use the second approach in GAMLSS:</p>
<div class="sourceCode" id="cb31"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb31-1"><a href="GLM.html#cb31-1"></a><span class="kw">library</span>(gamlss)</span>
<span id="cb31-2"><a href="GLM.html#cb31-2"></a>m6 &lt;-<span class="st"> </span><span class="kw">gamlss</span>(</span>
<span id="cb31-3"><a href="GLM.html#cb31-3"></a>  TP <span class="op">~</span><span class="st"> </span><span class="kw">pb</span>(TSS)</span>
<span id="cb31-4"><a href="GLM.html#cb31-4"></a>  ,<span class="dt">sigma.formula =</span> <span class="op">~</span>TSS</span>
<span id="cb31-5"><a href="GLM.html#cb31-5"></a>  ,<span class="dt">family =</span> GA</span>
<span id="cb31-6"><a href="GLM.html#cb31-6"></a>  ,<span class="dt">data =</span> D</span>
<span id="cb31-7"><a href="GLM.html#cb31-7"></a>  <span class="co">#,control = gamlss.control(n.cyc = 100, c.crit = 0.9)</span></span>
<span id="cb31-8"><a href="GLM.html#cb31-8"></a>)</span></code></pre></div>
<pre><code>## GAMLSS-RS iteration 1: Global Deviance = -821.986 
## GAMLSS-RS iteration 2: Global Deviance = -825.3166 
## GAMLSS-RS iteration 3: Global Deviance = -825.8326 
## GAMLSS-RS iteration 4: Global Deviance = -825.8686 
## GAMLSS-RS iteration 5: Global Deviance = -825.8733 
## GAMLSS-RS iteration 6: Global Deviance = -825.874</code></pre>
<div class="sourceCode" id="cb33"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb33-1"><a href="GLM.html#cb33-1"></a><span class="kw">summary</span>(m6)</span></code></pre></div>
<pre><code>## ******************************************************************
## Family:  c(&quot;GA&quot;, &quot;Gamma&quot;) 
## 
## Call:  gamlss(formula = TP ~ pb(TSS), sigma.formula = ~TSS,  
##     family = GA, data = D) 
## 
## Fitting method: RS() 
## 
## ------------------------------------------------------------------
## Mu link function:  log
## Mu Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) -3.70262    0.03757  -98.56   &lt;2e-16 ***
## pb(TSS)      0.03220    0.00112   28.75   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## ------------------------------------------------------------------
## Sigma link function:  log
## Sigma Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) -0.921346   0.092819  -9.926  &lt; 2e-16 ***
## TSS         -0.023435   0.004775  -4.908 2.82e-06 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## ------------------------------------------------------------------
## NOTE: Additive smoothing terms exist in the formulas: 
##  i) Std. Error for smoothers are for the linear effect only. 
## ii) Std. Error for the linear terms maybe are not accurate. 
## ------------------------------------------------------------------
## No. of observations in the fit:  133 
## Degrees of Freedom for the fit:  8.420713
##       Residual Deg. of Freedom:  124.5793 
##                       at cycle:  6 
##  
## Global Deviance:     -825.874 
##             AIC:     -809.0326 
##             SBC:     -784.6938 
## ******************************************************************</code></pre>
<p>In this case, we model both parameters of the distribution:
<span class="math display">\[TP_i \sim Gamma(\mu_i, \sigma_i)\]</span>
<span class="math display">\[\ln(\text{E}(TP_i)) = \ln(\mu_i) =  \beta_0 + f(TSS_i)\]</span>
<span class="math display">\[\ln(\sigma_i) = c_0 + c_1TSS_i\]</span></p>
<div class="sourceCode" id="cb35"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb35-1"><a href="GLM.html#cb35-1"></a><span class="kw">term.plot</span>(m6, <span class="dt">las =</span> <span class="dv">1</span>, <span class="dt">se =</span> <span class="ot">TRUE</span>, <span class="dt">ylim =</span> <span class="st">&quot;common&quot;</span>)</span></code></pre></div>
<p><img src="Lecture-notes-1_files/figure-html/unnamed-chunk-25-1.png" width="672" /></p>
<div class="sourceCode" id="cb36"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb36-1"><a href="GLM.html#cb36-1"></a><span class="kw">plot</span>(m6)</span></code></pre></div>
<p><img src="Lecture-notes-1_files/figure-html/unnamed-chunk-26-1.png" width="672" /></p>
<pre><code>## ******************************************************************
##        Summary of the Quantile Residuals
##                            mean   =  -0.0008679401 
##                        variance   =  1.007634 
##                coef. of skewness  =  0.3308549 
##                coef. of kurtosis  =  2.612453 
## Filliben correlation coefficient  =  0.988048 
## ******************************************************************</code></pre>
<div class="sourceCode" id="cb38"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb38-1"><a href="GLM.html#cb38-1"></a><span class="kw">plot</span>(TP <span class="op">~</span><span class="st"> </span>TSS, <span class="dt">data =</span> D, <span class="dt">las =</span> <span class="dv">1</span>)</span>
<span id="cb38-2"><a href="GLM.html#cb38-2"></a>pr &lt;-<span class="st"> </span><span class="kw">predict</span>(m6, <span class="dt">type =</span> <span class="st">&quot;response&quot;</span>)</span>
<span id="cb38-3"><a href="GLM.html#cb38-3"></a><span class="kw">with</span>(D, <span class="kw">lines</span>(<span class="dt">x =</span> <span class="kw">sort</span>(TSS), <span class="dt">y =</span> pr[<span class="kw">order</span>(TSS)],</span>
<span id="cb38-4"><a href="GLM.html#cb38-4"></a>              <span class="dt">lwd =</span> <span class="dv">2</span>, <span class="dt">col =</span> <span class="st">&quot;blue&quot;</span>))</span></code></pre></div>
<p><img src="Lecture-notes-1_files/figure-html/unnamed-chunk-27-1.png" width="672" /></p>
</div>
<div id="next-steps" class="section level3">
<h3><span class="header-section-number">1.2.7</span> Next steps</h3>
<p>We have considered several models for the pair TP ~ TSS, without considering other variables yet. Need to carefully select an appropriate distribution family for modeling.</p>
<p>When modeling with smoothers we should consider the issue of concurvity (an analogue of collinearity in linear models), when smooth transformations of predictors ‘look alike.’ There are functions to check concurvity in R.</p>
<div class="sourceCode" id="cb39"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb39-1"><a href="GLM.html#cb39-1"></a>m7 &lt;-<span class="st"> </span><span class="kw">gam</span>(TP <span class="op">~</span><span class="st"> </span><span class="kw">s</span>(TSS) <span class="op">+</span><span class="st"> </span><span class="kw">s</span>(SALINITY) <span class="op">+</span><span class="st"> </span><span class="kw">s</span>(TN) <span class="op">+</span><span class="st"> </span><span class="kw">s</span>(WTEMP), </span>
<span id="cb39-2"><a href="GLM.html#cb39-2"></a>          <span class="dt">data =</span> D, <span class="dt">family =</span> <span class="kw">Gamma</span>(<span class="dt">link =</span> log))</span>
<span id="cb39-3"><a href="GLM.html#cb39-3"></a><span class="kw">summary</span>(m7)</span></code></pre></div>
<pre><code>## 
## Family: Gamma 
## Link function: log 
## 
## Formula:
## TP ~ s(TSS) + s(SALINITY) + s(TN) + s(WTEMP)
## 
## Parametric coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) -3.25604    0.01556  -209.2   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Approximate significance of smooth terms:
##               edf Ref.df      F p-value    
## s(TSS)      6.595  7.617 29.353  &lt;2e-16 ***
## s(SALINITY) 6.923  7.966 10.892  &lt;2e-16 ***
## s(TN)       1.000  1.000  0.519   0.473    
## s(WTEMP)    7.342  8.298  7.683  &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## R-sq.(adj) =  0.886   Deviance explained = 92.4%
## GCV = 0.035873  Scale est. = 0.032206  n = 133</code></pre>
<div class="sourceCode" id="cb41"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb41-1"><a href="GLM.html#cb41-1"></a><span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">4</span>))</span>
<span id="cb41-2"><a href="GLM.html#cb41-2"></a><span class="kw">plot</span>(m7)</span></code></pre></div>
<p><img src="Lecture-notes-1_files/figure-html/unnamed-chunk-28-1.png" width="672" /></p>
<div class="sourceCode" id="cb42"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb42-1"><a href="GLM.html#cb42-1"></a><span class="kw">concurvity</span>(m7)</span></code></pre></div>
<pre><code>##                  para    s(TSS) s(SALINITY)     s(TN)  s(WTEMP)
## worst    2.255338e-24 0.8492033   0.9328362 0.9342809 0.8218917
## observed 2.255338e-24 0.6554349   0.9203188 0.7103660 0.3510102
## estimate 2.255338e-24 0.5150905   0.8471733 0.5209155 0.7415149</code></pre>
<div class="sourceCode" id="cb44"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb44-1"><a href="GLM.html#cb44-1"></a><span class="kw">concurvity</span>(m7, <span class="dt">full =</span> <span class="ot">FALSE</span>)<span class="op">$</span>estimate</span></code></pre></div>
<pre><code>##                     para       s(TSS)  s(SALINITY)        s(TN)     s(WTEMP)
## para        1.000000e+00 1.696166e-27 1.054164e-28 2.357477e-28 6.180660e-28
## s(TSS)      7.907947e-25 1.000000e+00 4.507004e-01 2.590425e-01 1.895382e-01
## s(SALINITY) 6.370609e-26 2.829094e-01 1.000000e+00 3.382813e-01 6.017203e-01
## s(TN)       1.318787e-25 2.477700e-01 7.128446e-01 1.000000e+00 5.096872e-01
## s(WTEMP)    4.200428e-25 2.441318e-01 4.495728e-01 2.178949e-01 1.000000e+00</code></pre>
<p>Variable selection in GAM is more tedious than in linear models. A general recommendation for GAM is to do forward-selection: include only relevant meaningful variables, do not just throw everything into the model. Note that the model can hold a mix of smoothed and non-smoothed terms. For example, remove TN, do not smooth SALINITY:</p>
<div class="sourceCode" id="cb46"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb46-1"><a href="GLM.html#cb46-1"></a>m8 &lt;-<span class="st"> </span><span class="kw">gam</span>(TP <span class="op">~</span><span class="st"> </span><span class="kw">s</span>(TSS) <span class="op">+</span><span class="st"> </span>SALINITY <span class="op">+</span><span class="st"> </span><span class="kw">s</span>(WTEMP), </span>
<span id="cb46-2"><a href="GLM.html#cb46-2"></a>          <span class="dt">data =</span> D, <span class="dt">family =</span> <span class="kw">Gamma</span>(<span class="dt">link =</span> log))</span>
<span id="cb46-3"><a href="GLM.html#cb46-3"></a><span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">3</span>))</span>
<span id="cb46-4"><a href="GLM.html#cb46-4"></a><span class="kw">plot</span>(m8)</span>
<span id="cb46-5"><a href="GLM.html#cb46-5"></a><span class="kw">concurvity</span>(m8, <span class="dt">full =</span> <span class="ot">FALSE</span>)<span class="op">$</span>estimate</span></code></pre></div>
<pre><code>##                  para       s(TSS)     s(WTEMP)
## para     1.000000e+00 1.696166e-27 6.180660e-28
## s(TSS)   7.944119e-25 1.000000e+00 1.895382e-01
## s(WTEMP) 4.226487e-25 2.441318e-01 1.000000e+00</code></pre>
<div class="sourceCode" id="cb48"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb48-1"><a href="GLM.html#cb48-1"></a><span class="co">#gam.check(m8)</span></span></code></pre></div>
<p><img src="Lecture-notes-1_files/figure-html/unnamed-chunk-31-1.png" width="672" /></p>

</div>
</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-Benjamin:etal:2003">
<p>Benjamin, M. A., R. A. Rigby, and D. M. Stasinopoulos. 2003. “Generalized Autoregressive Moving Average Models.” <em>Journal of the American Statistical Association</em> 98 (461): 214–23. <a href="https://doi.org/10.1198/016214503388619238">https://doi.org/10.1198/016214503388619238</a>.</p>
</div>
<div id="ref-Chatterjee:Hadi:2006">
<p>Chatterjee, S., and A. S. Hadi. 2006. <em>Regression Analysis by Example</em>. Hoboken, New Jersey: John Wiley &amp; Sons.</p>
</div>
<div id="ref-Hastie:etal:2009">
<p>Hastie, T. J., R. J. Tibshirani, and J. H. Friedman. 2009. <em>The Elements of Statistical Learning: Data Mining, Inference, and Prediction</em>. 2nd ed. New York: Springer. <a href="https://doi.org/10.1007/978-0-387-84858-7">https://doi.org/10.1007/978-0-387-84858-7</a>.</p>
</div>
<div id="ref-Kohn:etal:2000">
<p>Kohn, R., M. G. Schimek, and M. Smith. 2000. “Spline and Kernel Regression for Dependent Data.” In <em>Smoothing and Regression: Approaches, Computation, and Application</em>, edited by M. G. Schimek, 135–58. New York: John Wiley &amp; Sons, Inc. <a href="https://doi.org/10.1002/9781118150658.ch6">https://doi.org/10.1002/9781118150658.ch6</a>.</p>
</div>
<div id="ref-Lyubchich:etal:2019:wires">
<p>Lyubchich, V., N. K. Newlands, A. Ghahari, T. Mahdi, and Y. R. Gel. 2019. “Insurance Risk Assessment in the Face of Climate Change: Integrating Data Science and Statistics.” <em>Wiley Interdisciplinary Reviews: Computational Statistics</em> 11: e1462. <a href="https://doi.org/10.1002/wics.1462">https://doi.org/10.1002/wics.1462</a>.</p>
</div>
<div id="ref-Stasinopoulos:Rigby:2007">
<p>Stasinopoulos, D. M., and R. A. Rigby. 2007. “Generalized Additive Models for Location Scale and Shape (GAMLSS) in R.” <em>Journal of Statistical Software</em> 23 (7): 1–46.</p>
</div>
<div id="ref-R-dplyr">
<p>Wickham, Hadley, Romain François, Lionel Henry, and Kirill Müller. 2020. <em>Dplyr: A Grammar of Data Manipulation</em>. <a href="https://CRAN.R-project.org/package=dplyr">https://CRAN.R-project.org/package=dplyr</a>.</p>
</div>
<div id="ref-Wood:2006book">
<p>Wood, S. N. 2006. <em>Generalized Additive Models: An Introduction with R</em>. New York: Chapman; Hall/CRC.</p>
</div>
<div id="ref-Zuur:etal:2009">
<p>Zuur, A., E. N. Ieno, N. J. Walker, A. A. Saveliev, and G. M. Smith. 2009. <em>Mixed Effects Models and Extensions in Ecology with R</em>. New York: Springer. <a href="https://doi.org/10.1007/978-0-387-87458-6">https://doi.org/10.1007/978-0-387-87458-6</a>.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="index.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="references.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/vlyubchich/LectureNotes1/edit/master/01-GLM.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["Lecture-notes-1.pdf", "Lecture-notes-1.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
